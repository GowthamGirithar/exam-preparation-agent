# LLM Configuration
# Choose between "ollama" or "openai"
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1
LLM_HOST=http://localhost:11434

# Universal API Key for any LLM provider (OpenAI, Anthropic, etc.)
# Only required when using providers that need API keys (not needed for Ollama)
LLM_PROVIDER_API_KEY=your_api_key_here

# Required for web search functionality
GOOGLE_SERPER_API_KEY=your_google_serper_api_key_here

# Tool Schema Validation (automatically set by agent factory)
# true = Use Pydantic schemas (OpenAI models)
# false = Use manual parsing (Ollama models)
TOOL_SCHEMA_VALIDATION=false

# Vector Store Configuration
VECTOR_STORE_PROVIDER=chroma
CHROMA_PERSIST_DIR=./chroma_db
EMBEDDING_PROVIDER=sentence_transformers
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2

# Collection Names
ENGLISH_COLLECTION=english
MICROSERVICE_COLLECTION=microservices
LAW_COLLECTION=law

# Agent Configuration
AGENT_NAME=InteractiveLearningAgent
MAX_ITERATIONS=5
VERBOSE_MODE=true
SEARCH_RESULTS_LIMIT=3

# LangSmith Configuration (Optional)
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=law-exam-agent-evaluation
LANGSMITH_API_URL=https://api.smith.langchain.com

# Evaluation Configuration
EVALUATION_LOCAL=true
CORRECTNESS_THRESHOLD=0.75
TOOL_SELECTION_THRESHOLD=0.90
RELEVANCE_THRESHOLD=0.80
COMPLETENESS_THRESHOLD=0.70
MEMORY_RETENTION_THRESHOLD=0.85

# Example configurations:

# For Ollama (local models):
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.1
# LLM_HOST=http://localhost:11434
# (No API key needed)

# For OpenAI:
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4
# LLM_PROVIDER_API_KEY=sk-your-openai-api-key-here

# For other providers (future support):
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-sonnet
# LLM_PROVIDER_API_KEY=your-anthropic-api-key-here
